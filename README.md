# ğŸ“š PDF Chat Assistant

A sleek AI-powered web app that lets you **chat with your PDFs** using cutting-edge LLMs like **Llama3** and **Mixtral**, via **Groq** and **Ollama**.

> Upload any PDF, ask questions, get smart contextual answers â€” like ChatGPT for your files!

---

![PDF Chat Assistant UI](image.png)

---

## ğŸŒ Live Demo

| ğŸ–¥ Frontend                                                                   | ğŸ“š API Docs                                                                            |
| ---------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| [chatapp-client-xs77.onrender.com](https://chatapp-client-xs77.onrender.com) | [chatapp-server-jeiz.onrender.com/docs](https://chatapp-server-jeiz.onrender.com/docs) |

---

## âœ¨ Features

- ğŸ§  AI-powered chat using **Llama3** or **Mixtral**
- ğŸ”„ Model switching between **Groq** (cloud) and **Ollama** (local)
- ğŸ“„ Upload and extract text from PDF files
- ğŸ’¬ Real-time chat with conversation memory
- ğŸ¨ Beautiful and responsive UI
- ğŸ›¡ï¸ Secure file handling
- âš¡ High-performance backend with **Bun** + **Elysia**

---

## ğŸ§‘â€ğŸ’» Tech Stack

| Frontend                          | Backend                        | Infra               |
| --------------------------------- | ------------------------------ | ------------------- |
| React + TypeScript + TailwindCSS  | Bun + Elysia.js + LangGraph    | Docker + Render.com |
| Vite, SWR, React Markdown, TipTap | PDF parser, Groq & Ollama LLMs | Docker Compose      |

---

## ğŸš€ Screenshots

### ğŸ“„ Upload PDF

![PDF Upload](https://github.com/rejisterjack/chatapp/assets/124599/0b8c6c9c-3e3d-42b2-8b0a-4b4c1d9e5b0a)

### ğŸ¤– AI Chat in Action

![AI Chat](https://github.com/rejisterjack/chatapp/assets/124599/4c6d8c8c-9d6a-4c05-8d5e-8b3a4a6f6f1d)

### ğŸ” Model Switching

![Model Switch](https://github.com/rejisterjack/chatapp/assets/124599/4e5c2e98-9aad-4b9b-85c0-6d4d4b9a7b6d)

---

## ğŸ§­ How It Works

```mermaid
graph TD
  A[User uploads PDF] --> B[Backend extracts text]
  B --> C[User sends question]
  C --> D[Backend forwards prompt to selected model]
  D --> E[LLM (Groq or Ollama)]
  E --> F[Model responds with answer]
  F --> G[Response shown in UI]
```

---

## âš™ï¸ Setup Guide

### ğŸ“¦ Requirements

- Node.js 20+
- Bun runtime
- Docker + Docker Compose (for full stack)
- Groq API Key (for Groq usage)
- [Ollama](https://ollama.com/) installed (optional for local inference)

---

### ğŸ”§ Local Development

```bash
# Clone repository
git clone https://github.com/rejisterjack/chatapp.git
cd chatapp

# Install dependencies
cd client && bun install      # Frontend
cd ../server && bun install  # Backend

# Run dev servers
cd client && bun run dev     # http://localhost:5173
cd ../server && bun run dev  # http://localhost:8080
```

---

### ğŸ³ Docker Setup

Run the complete app stack with:

```bash
docker-compose up --build
```

- Frontend: `http://localhost:5173`
- Backend: `http://localhost:8080`
- API Docs: `http://localhost:8080/docs`

---

## ğŸ” Environment Variables

### Frontend (`client/.env`)

```env
VITE_API_BASE_URL=http://localhost:8080
```

### Backend (`server/.env`)

```env
PORT=8080
USE_OLLAMA=true
OLLAMA_HOST=http://ollama:11434
GROQ_API_KEY=your-groq-api-key
```

---

## ğŸ“¡ API Overview

### `GET /`

Health check  
â†’ `{ "status": "ok" }`

### `GET /api/models`

Returns available models  
â†’ `["groq", "ollama"]`

### `POST /api/upload`

Upload a PDF  
â†’ Returns extracted text preview and `conversationId`

### `POST /api/chat`

Send a message to the assistant  
â†’ `{ response: "Answer from model" }`

---

## ğŸ§  Model Switching

You can dynamically switch between:

- ğŸŒ **Groq** (cloud-based) â€” fast and powerful LLMs like `llama3-8b`
- ğŸ–¥ï¸ **Ollama** (local) â€” run `llama3` or `mixtral` locally

Switch via environment config:

```bash
USE_OLLAMA=true # or false
```

Or by frontend toggle (coming soon ğŸš§)

---

## ğŸ›  Folder Structure

```
chatapp/
â”œâ”€â”€ client/       # React frontend
â””â”€â”€ server/       # Bun + Elysia backend
```

---

## ğŸ§‘â€ğŸ’» Contributing

1. Fork the repo
2. Create your feature branch  
   `git checkout -b feature/amazing-feature`
3. Commit your changes  
   `git commit -m "Add amazing feature"`
4. Push and open a PR ğŸ‰

---

## ğŸ“„ License

MIT License. See [LICENSE](./LICENSE)

---

Made with â¤ï¸ by [@rejisterjack](https://github.com/rejisterjack)
